{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d95a5f",
   "metadata": {},
   "source": [
    "## Projet : Employee-Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f39fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier,DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import stddev, avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b076d0f4",
   "metadata": {},
   "source": [
    "## chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e788605",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('attrition').getOrCreate()\n",
    "file_location = \"HR-Employee-Attrition.csv\"\n",
    "file_type = \"csv\"\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".option(\"header\", first_row_is_header) \\\n",
    ".option(\"sep\", delimiter) \\\n",
    ".load(file_location)\n",
    "\n",
    "df = df.drop(\"Over18\")\n",
    "df = df.drop(\"EmployeeCount\")\n",
    "df = df.drop(\"StandardHours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66457905",
   "metadata": {},
   "source": [
    "## grid pour les modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4acb80e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(featuresCol='features', labelCol='label')\n",
    "param_grid_gbt = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [2, 4, 6]) \\\n",
    "    .addGrid(gbt.maxBins, [20, 30]) \\\n",
    "    .addGrid(gbt.maxIter, [10, 20, 30]) \\\n",
    "    .build()\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label')\n",
    "param_grid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [2]) \\\n",
    "    .addGrid(rf.maxBins, [20]) \\\n",
    "    .addGrid(rf.numTrees, [10]) \\\n",
    "    .build()\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "param_grid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.05, 0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea59459",
   "metadata": {},
   "source": [
    "## fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f858d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(df):\n",
    "    # convertir les colonnes string en double quand cela est possible\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            if int(df.select(column).first()[0]):\n",
    "                df = df.withColumn(column, col(column).cast(\"double\"))\n",
    "        except:\n",
    "            pass\n",
    "    return df\n",
    "        \n",
    "def remove_outliers(df):\n",
    "\n",
    "    # Boucle pour enlever les valeurs aberrantes de chaque colonne\n",
    "    for col in df.columns:\n",
    "        # Calcul des statistiques pour la colonne\n",
    "        stats = df.select(avg(col), stddev(col)).first()\n",
    "        mean = stats[0]\n",
    "        std = stats[1]  \n",
    "        if mean is not None and std is not None:\n",
    "            # Calcul du seuil pour déterminer les valeurs aberrantes\n",
    "            threshold = 3 * std + mean     \n",
    "            # Suppression des valeurs aberrantes pour la colonne\n",
    "            df = df.filter(df[col] <= threshold)\n",
    "    return df\n",
    "\n",
    "\n",
    "def assembler_for_pipeline(df, label):\n",
    "    categoricalColumns = [col for (col, dtype) in df.dtypes if dtype == \"string\" and col != label]\n",
    "    stages = []\n",
    "\n",
    "    for categoricalCol in categoricalColumns:\n",
    "        stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "        encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "        stages += [stringIndexer, encoder]\n",
    "    \n",
    "    label_stringIdx = StringIndexer(inputCol=label, outputCol=\"label\")\n",
    "    stages += [label_stringIdx]\n",
    "\n",
    "    numericCols = [col for (col, dtype) in df.dtypes if dtype.startswith('double') and col != \"label\"]\n",
    "    assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "    return assembler, stages\n",
    "\n",
    "def model_for_pipeline(classifier, param_grid):\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol='label')\n",
    "    cv = CrossValidator(estimator=classifier, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "    return cv\n",
    "\n",
    "def view_feature_importances(df):\n",
    "    \n",
    "    assembler, stages = assembler_for_pipeline(df, 'Attrition')\n",
    "    rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(rf.numTrees, [10, 20]) \\\n",
    "        .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "        .build()\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "    train, test = df.randomSplit([0.8, 0.2])\n",
    "    stages += [assembler, rf]\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    \n",
    "    pipelineModel = pipeline.fit(train)\n",
    "    predictions = pipelineModel.transform(test)\n",
    "    auc = evaluator.evaluate(predictions)\n",
    "    print(\"AUC-ROC = %g\" % auc)\n",
    "    \n",
    "    importances = pipelineModel.stages[-1].featureImportances.toArray()\n",
    "    cols = df.columns\n",
    "    selectedcols = [\"label\", \"features\"] + cols\n",
    "    cols_importances = list(zip(selectedcols, importances))\n",
    "    sorted_cols_importances = sorted(cols_importances, key=lambda x: x[1], reverse=True)\n",
    "    print(\"Colonnes triées par ordre d'importance décroissante :\")\n",
    "    for col, importance in sorted_cols_importances:\n",
    "        print(col, \"=\", importance)\n",
    "        \n",
    "    return sorted_cols_importances\n",
    "        \n",
    "def pipelinedata(df, assembler, stages, model):\n",
    "    \n",
    "    stages += [assembler, model]\n",
    "    train, test = df.randomSplit([0.8, 0.2])\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    pipelineModel = pipeline.fit(train)\n",
    "    predictions = pipelineModel.transform(test)\n",
    "    predictions.take(1)\n",
    "    selected = predictions.select(\"label\", \"prediction\", \"rawPrediction\", \"probability\")\n",
    "    display(selected)\n",
    "    return model, predictions, selected\n",
    "\n",
    "def metrics(predictions, model):\n",
    "\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "    auc_roc = evaluator.evaluate(predictions)\n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(model + \": courbe ROC = %g\" % auc_roc)\n",
    "    print(model + \": précision = %g\" % accuracy)\n",
    "    print(model + \": RMSE = %g\" % rmse)\n",
    "    \n",
    "def filter_most_important_columns(df, sorted_cols_importances):\n",
    "    selected_cols = [col for col, importance in sorted_cols_importances if importance > 0.01]\n",
    "    if \"features\" in selected_cols:\n",
    "        selected_cols.remove(\"features\")\n",
    "    if \"label\" in selected_cols:\n",
    "        selected_cols.remove(\"label\")\n",
    "    df = df.select(selected_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ea14a",
   "metadata": {},
   "source": [
    "## Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f26880ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_to_int(df)\n",
    "df = remove_outliers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f99576",
   "metadata": {},
   "source": [
    "## Analyse de l'importance des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08392c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC = 0.757249\n",
      "Colonnes triées par ordre d'importance décroissante :\n",
      "MonthlyRate = 0.09995755918827355\n",
      "NumCompaniesWorked = 0.04767685195930893\n",
      "MonthlyIncome = 0.027335017109355646\n",
      "Age = 0.013141824061761028\n",
      "EmployeeNumber = 0.012896362693972225\n",
      "YearsSinceLastPromotion = 0.012353609360885384\n",
      "features = 0.010871588843403399\n",
      "TotalWorkingYears = 0.01081078066777602\n",
      "OverTime = 0.010579889291449242\n",
      "EnvironmentSatisfaction = 0.009779080343573937\n",
      "YearsWithCurrManager = 0.009198619971385671\n",
      "Department = 0.007645710022962007\n",
      "Gender = 0.007252614369424988\n",
      "label = 0.006228258243485643\n",
      "MaritalStatus = 0.00558500168252136\n",
      "JobSatisfaction = 0.0034972692462091\n",
      "YearsAtCompany = 0.0032789144803145403\n",
      "JobLevel = 0.003188733095991534\n",
      "StockOptionLevel = 0.0026172003735815373\n",
      "PercentSalaryHike = 0.002437299009961595\n",
      "PerformanceRating = 0.0024107384981124375\n",
      "TrainingTimesLastYear = 0.0018966803895070741\n",
      "BusinessTravel = 0.0017382937130864412\n",
      "JobInvolvement = 0.0016130330273097613\n",
      "Attrition = 0.0010649346184432797\n",
      "Education = 0.001013871255618038\n",
      "EducationField = 0.0009226982796659941\n",
      "RelationshipSatisfaction = 0.0009092700594095391\n",
      "DistanceFromHome = 0.0008954758646341805\n",
      "YearsInCurrentRole = 0.0008811498668489423\n",
      "HourlyRate = 0.0004809853048958209\n",
      "DailyRate = 0.0\n",
      "JobRole = 0.0\n",
      "WorkLifeBalance = 0.0\n"
     ]
    }
   ],
   "source": [
    "sorted_cols_importances = view_feature_importances(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f23b3",
   "metadata": {},
   "source": [
    "## Garder les colonnes les plus importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5b6c6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_most_important_columns(df, sorted_cols_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8b0e8095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-------------+--------+--------+---------+--------------------+------+-------------+\n",
      "|MonthlyRate|NumCompaniesWorked|MonthlyIncome|JobLevel|OverTime|Attrition|YearsWithCurrManager|Gender|MaritalStatus|\n",
      "+-----------+------------------+-------------+--------+--------+---------+--------------------+------+-------------+\n",
      "|    19479.0|               8.0|       5993.0|     2.0|     Yes|      Yes|                 5.0|Female|       Single|\n",
      "|    24907.0|               1.0|       5130.0|     2.0|      No|       No|                 7.0|  Male|      Married|\n",
      "|     2396.0|               6.0|       2090.0|     1.0|     Yes|      Yes|                 0.0|  Male|       Single|\n",
      "|    23159.0|               1.0|       2909.0|     1.0|     Yes|       No|                 0.0|Female|      Married|\n",
      "|    16632.0|               9.0|       3468.0|     1.0|      No|       No|                 2.0|  Male|      Married|\n",
      "|    11864.0|               0.0|       3068.0|     1.0|      No|       No|                 6.0|  Male|       Single|\n",
      "|     9964.0|               4.0|       2670.0|     1.0|     Yes|       No|                 0.0|Female|      Married|\n",
      "|    13335.0|               1.0|       2693.0|     1.0|      No|       No|                 0.0|  Male|     Divorced|\n",
      "|     8787.0|               0.0|       9526.0|     3.0|      No|       No|                 8.0|  Male|       Single|\n",
      "|    16577.0|               6.0|       5237.0|     2.0|      No|       No|                 7.0|  Male|      Married|\n",
      "+-----------+------------------+-------------+--------+--------+---------+--------------------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c162948",
   "metadata": {},
   "source": [
    "## Modelisation avec les champs filtrés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "157d47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gbt = df\n",
    "df_rf = df\n",
    "df_lr = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fdbbf",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "effa289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = convert_to_int(df_rf)\n",
    "df_rf = remove_outliers(df_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2b14a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler, stages = assembler_for_pipeline(df_rf, 'Attrition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6fe11607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, prediction: double, rawPrediction: vector, probability: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: courbe ROC = 0.704139\n",
      "rf: précision = 0.848361\n",
      "rf: RMSE = 0.389409\n"
     ]
    }
   ],
   "source": [
    "model_rf = model_for_pipeline(rf, param_grid_rf)\n",
    "model_rf, predictions_rf, selected_rf = pipelinedata(df_rf, assembler, stages, model_rf)\n",
    "metrics(predictions_rf, 'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517a4c20",
   "metadata": {},
   "source": [
    "### gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "640e84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gbt = convert_to_int(df_gbt)\n",
    "df_gbt = remove_outliers(df_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c66202e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler, stages = assembler_for_pipeline(df_gbt, 'Attrition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a7977eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, prediction: double, rawPrediction: vector, probability: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt: courbe ROC = 0.795025\n",
      "gbt: précision = 0.828685\n",
      "gbt: RMSE = 0.413902\n"
     ]
    }
   ],
   "source": [
    "model_gbt = model_for_pipeline(gbt, param_grid_gbt)\n",
    "model_gbt, predictions_gbt, selected_gbt = pipelinedata(df_gbt, assembler, stages, model_gbt)\n",
    "metrics(predictions_gbt, 'gbt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929991ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52492225",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a1add3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = convert_to_int(df_lr)\n",
    "df_lr = remove_outliers(df_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e1099a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler, stages = assembler_for_pipeline(df_lr, 'Attrition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a8d6b0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, prediction: double, rawPrediction: vector, probability: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: courbe ROC = 0.76598\n",
      "lr: précision = 0.818898\n",
      "lr: RMSE = 0.425561\n"
     ]
    }
   ],
   "source": [
    "model_lr = model_for_pipeline(lr, param_grid_lr)\n",
    "model_lr, predictions_lr, selected_lr = pipelinedata(df_lr, assembler, stages, model_lr)\n",
    "metrics(predictions_lr, 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011bb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa63631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab45bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e0bb95c",
   "metadata": {},
   "source": [
    "### j'ai pas utilisé cette partie, je te laisse modifié si besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3e55402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #paramétres\n",
    "# def params(nom, nb_model, train, test):\n",
    "#     liste = range(1, 20)\n",
    "\n",
    "#     best_accuracy = 0\n",
    "#     best_nb = 0\n",
    "\n",
    "#     for nb in liste:\n",
    "#         model_choix = [LogisticRegression(labelCol = 'label', featuresCol = 'features', maxIter= nb),\n",
    "#         DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=nb, seed =40),\n",
    "#         GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=nb, seed =40),\n",
    "#         RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=nb, seed =40)]\n",
    "\n",
    "#         model = model_choix[nb_model]\n",
    "#         trained_model = model.fit(train)\n",
    "#         predictions = trained_model.transform(test)\n",
    "#         evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "#         accuracy = evaluator.evaluate(predictions)\n",
    "    \n",
    "#         # meilleure précision\n",
    "#         if accuracy > best_accuracy:\n",
    "#             best_accuracy = accuracy\n",
    "#             best_nb = nb\n",
    "        \n",
    "#     print(\"la meilleure précision pour \" + nom + \" :\", best_accuracy)\n",
    "#     print(\"le meilleur nombre pour paramétre \" + nom + \" :\", best_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb832a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "modelg.save(\"Model\")\n",
    "shutil.make_archive('Model', 'zip','./content/Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a67e943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f07bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d785f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
